{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "import lightgbm as lgbmfrom\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "import catboost as catb\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, learning_curve\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from vecstack import stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "def make_predictions(filename, model):\n",
    "    df_test = pd.read_csv('./data/test.csv')\n",
    "    data_test = job(df_test)\n",
    "\n",
    "    X_train_t, X_test_t, y_train_t, y_test_t, y_t, X_t, data_t, ids_t = get_data(False, data_test)\n",
    "\n",
    "    y_predict =  model.predict(X_t)\n",
    "    is_default = pd.DataFrame({'Id': ids_t,'Outcome':y_predict})\n",
    "\n",
    "    is_default.to_csv(filename, index=False)\n",
    "\n",
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('Train subset\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('Test subset\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "\n",
    "def fit_and_show(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    get_classification_report(y_train, y_train_pred, y_test, y_test_pred) \n",
    "\n",
    "def get_data(load, dt):\n",
    "  \n",
    "    if load:\n",
    "        data = pd.read_pickle('work_data4.pkl')\n",
    "    else:\n",
    "        data = dt\n",
    "\n",
    "    target = 'Outcome'  \n",
    "    if 'Outcome' in data.columns:\n",
    "        y = data[target]\n",
    "    else:\n",
    "        y = data['Id']\n",
    "        data[target] = data['Id']        \n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    ids = data['Id']\n",
    "\n",
    "    X = scaler.fit_transform(data.drop([target, 'Id'], axis=1))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, shuffle=True, test_size=0.05, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, y, X, data, ids\n",
    "\n",
    "\n",
    "def correct_value(data, target, value):\n",
    "    data.loc[data[target] < value, target] = data[target].median()\n",
    "    return data\n",
    "\n",
    "# генераторы признаков квадраты и логорифмы\n",
    "def create_poly_features(data, num_features):\n",
    "    poly_features = np.power(data[num_features], 2)\n",
    "    poly_features = poly_features.rename(columns=dict(zip(data.columns, [col+' sqr' for col in data.columns])))\n",
    "    return data.join(poly_features)\n",
    "\n",
    "def create_log_features(data, num_features):\n",
    "    log_features = np.log(data[num_features], where=data[num_features]>0)\n",
    "    log_features = log_features.rename(columns=dict(zip(data.columns, [col+'_log' for col in data.columns])))\n",
    "    return data.join(log_features)\n",
    "\n",
    "# Подготовим функцию обработки дата сета\n",
    "def job(data):\n",
    "      # Заменим тех у кого не измерили глюкозу на средние значения\n",
    "      data = correct_value(data, 'Glucose', 60)\n",
    "      # Установим средние значения для кровянного давления, у кого не измерили\n",
    "      data = correct_value(data, 'BloodPressure', 60)\n",
    "      # Установим средние значения тех у кого индекс массы тела меньше 18\n",
    "      data = correct_value(data,'BMI', 18)\n",
    "      # откорректируем толщину кожы в 5 мм так как этот фактор влияет на усвоение инсулина, и его нужно было измерять, тут явно пропуски\n",
    "      data = correct_value(data,'SkinThickness', 5)\n",
    "      # Откорректируем нижнюю границу нормы по инсулину\n",
    "      data = correct_value(data,'Insulin', 15)\n",
    "\n",
    "      #data=data.drop(['BloodPressure', 'SkinThickness', 'Insulin'], axis=1)\n",
    "      #data=data.drop(['Insulin'], axis=1)\n",
    "      \n",
    "      # Добавим логарифмы и квадраты для числовых переменных\n",
    "      data = create_poly_features(data, num_features)\n",
    "      data = create_log_features(data, num_features)\n",
    "      return data\n",
    "num_features = ['Pregnancies', 'Glucose', 'BMI', 'Age'] # Insulin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, y, X, data, ids = get_data(True, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train subset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.79       337\n",
      "           1       0.61      0.70      0.65       187\n",
      "\n",
      "    accuracy                           0.73       524\n",
      "   macro avg       0.72      0.73      0.72       524\n",
      "weighted avg       0.75      0.73      0.74       524\n",
      "\n",
      "Test subset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        17\n",
      "           1       0.78      0.64      0.70        11\n",
      "\n",
      "    accuracy                           0.79        28\n",
      "   macro avg       0.78      0.76      0.77        28\n",
      "weighted avg       0.78      0.79      0.78        28\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 0.001,\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "metadata": {},
     "execution_count": 572
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C' : [0.001, 0.01, 0.015, 0.1],\n",
    "    'solver' : ['liblinear', 'lgfbs', 'sag', 'saga'],\n",
    "    'max_iter': [1000, 1500, 2000],\n",
    "    'multi_class':['ovr', 'multinormal', 'auto']\n",
    "    },\n",
    "\n",
    "lg = LogisticRegression(random_state= 42)\n",
    "lgs = GridSearchCV(lg, param_grid, n_jobs=-1, cv=5, scoring = 'f1')\n",
    "\n",
    "fit_and_show(lgs, X_train, X_test, y_train, y_test)\n",
    "lgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(\n",
    "    solver='liblinear',\n",
    "    C=0.001,\n",
    "    max_iter= 1000,\n",
    "    multi_class= 'ovr',\n",
    "    penalty='l2',\n",
    "      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(\n",
    "     multi_class='auto',\n",
    "     solver='liblinear',\n",
    "      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3 = LogisticRegression(\n",
    "solver='liblinear',\n",
    "multi_class='auto',\n",
    "\n",
    "max_iter=1000,\n",
    "penalty='l2',\n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "                    max_depth=3,\n",
    "                    min_samples_leaf=5,\n",
    "                    criterion='entropy',\n",
    "                    min_samples_split=5,\n",
    "                    class_weight='balanced',\n",
    "                    max_leaf_nodes=12,\n",
    "                    random_state=43,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(\n",
    "    RandomForestClassifier(\n",
    "        max_depth=2,\n",
    "        min_samples_leaf=5,\n",
    "        criterion='entropy',\n",
    "        min_samples_split=5,\n",
    "        class_weight='balanced',\n",
    "        max_leaf_nodes=12,\n",
    "        random_state=43,\n",
    "        n_jobs=-1),\n",
    "    \n",
    "    algorithm='SAMME',\n",
    "    random_state=43,\n",
    "    learning_rate=0.11,\n",
    "    n_estimators=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbt = LGBMClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=2,\n",
    "        metric='f1',\n",
    "        n_estimators=90,\n",
    "        random_state=42,\n",
    "        reg_alpha=1,\n",
    "        reg_lambda=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(\n",
    "    max_depth=2,\n",
    "    min_samples_leaf=5,\n",
    "    min_samples_split=5,\n",
    "    max_leaf_nodes=12,\n",
    "    random_state=43,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners3 = [\n",
    "    ('rf_1', ada),\n",
    "    ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = LogisticRegression(multi_class='auto', solver='liblinear', random_state=42)\n",
    "sclf_st = StackingClassifier(estimators=base_learners3, final_estimator=lr3, cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train subset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86       337\n",
      "           1       0.75      0.76      0.76       187\n",
      "\n",
      "    accuracy                           0.83       524\n",
      "   macro avg       0.81      0.81      0.81       524\n",
      "weighted avg       0.83      0.83      0.83       524\n",
      "\n",
      "Test subset\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        17\n",
      "           1       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.89        28\n",
      "   macro avg       0.93      0.86      0.88        28\n",
      "weighted avg       0.91      0.89      0.89        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit_and_show(sclf_st, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions('predictions_stack2.csv', sclf_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}